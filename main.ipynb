{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel, get_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "import pandas as pd\n",
    "\n",
    "num_epochs = 2\n",
    "lr = 5e-5                                           \n",
    "batch_size = 1\n",
    "warmup_steps= 750\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-large\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"MuskumPillerum/General-Knowledge\")\n",
    "# dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dataset = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "# data_format = 'Question:' + 'Answer: '\n",
    "# ct = 0\n",
    "# for example in dataset:\n",
    "#     try:\n",
    "#         input_text =  'Question:'+ example['Question']+ ' Answer: ' + example['Answer']\n",
    "#         encoded_data = tokenizer('' + input_text + '', truncation=True, max_length=768, padding=\"max_length\")\n",
    "#         new_dataset['input_ids'].append(encoded_data['input_ids'])\n",
    "#         new_dataset['attention_mask'].append(encoded_data['attention_mask'])\n",
    "#     except:\n",
    "#         ct += 1\n",
    "\n",
    "# new_dataset = Dataset.from_dict(new_dataset)\n",
    "# new_dataset.set_format(\"torch\")\n",
    "\n",
    "# # DataLoader\n",
    "# dataloader = DataLoader(new_dataset, shuffle=True, batch_size=batch_size, pin_memory=True)\n",
    "# ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          മറ്റുള്ളവരെ കുറിച്ചു ചിന്തിക്കുന്നത്‌ മറ്റൊരു ...\n",
       "1          ഓസ്ട്രേലിയൻ സർവീസ് ടീമിനെതിരെ ബാറ്റ് ചെയ്ത ബ്ര...\n",
       "2                                          പുറത്ത്‌ മഞ്ഞുമഴ.\n",
       "3                                 അതിന് ശേഷം ഇലക്ട്രിക് ബസ്.\n",
       "4          മലയാളം, കന്നഡ, തമിഴ് തുടങ്ങിയ ഭാഷകളിൽ ശ്രദ്ധേയ...\n",
       "                                 ...                        \n",
       "6050951                      മദ്യപാനം ശരീരത്തിന് ഹാനികരമാണ്.\n",
       "6050952                                  അങ്ങേര് നല്ല ഉശിരൻ.\n",
       "6050953    നെല്ലും വാഴയും പച്ചക്കറികളും മരച്ചീനിയുമുൾപ്പെ...\n",
       "6050954                           എളുപ്പത്തില്‍ അടുക്കാറില്ല\n",
       "6050955    സംഭവം കൊലപാതകമാണെന്ന് സംശയിക്കുന്നതായി പൊലീസ് ...\n",
       "Name: Text, Length: 6050956, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('malayalam_dataset.csv')['Text']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = {'input_ids': [], 'attention_mask': []}\n",
    "wrong_data = 0\n",
    "for i,data in enumerate(dataset):\n",
    "    if i%1e5: print()\n",
    "    try:\n",
    "        encoded_data = tokenizer(data+'', truncation=True, max_length=768, padding=\"max_length\")\n",
    "        new_dataset['input_ids'].append(encoded_data['input_ids'])\n",
    "        new_dataset['attention_mask'].append(encoded_data['attention_mask'])\n",
    "    except:\n",
    "        wrong_data += 1\n",
    "wrong_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = Dataset.from_dict(new_dataset)\n",
    "new_dataset.set_format(\"torch\")\n",
    "dataloader = DataLoader(new_dataset, shuffle=True, batch_size=batch_size, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_steps = num_epochs * len(dataloader)\n",
    "lr_scheduler = get_scheduler(name=\"linear\", optimizer=optimizer, num_warmup_steps=warmup_steps, num_training_steps=num_training_steps)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)\n",
    "model = torch.compile(model)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_loc = '/home/arjun/Desktop/Model_save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = tqdm(range(num_training_steps-1), desc='Training', unit='steps')\n",
    "model.train()\n",
    "ep = 0\n",
    "prev_avg_train_loss = 999\n",
    "for epoch in range(num_epochs):\n",
    "    total_train_loss = 0\n",
    "    for batch in dataloader:\n",
    "        batch_data = batch['input_ids'].to(device)\n",
    "        attention = batch['attention_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(batch_data,\n",
    "                            labels=batch_data,\n",
    "                            attention_mask=attention,\n",
    "                            token_type_ids=None\n",
    "                            )\n",
    "\n",
    "            loss = outputs[0]\n",
    "            batch_loss = loss.item()\n",
    "            total_train_loss += batch_loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(dataloader)\n",
    "    ep += 1\n",
    "    print('Epoch:', ep, 'Average training loss =', avg_train_loss)\n",
    "    if abs(prev_avg_train_loss - avg_train_loss) < 0.0001:\n",
    "        model.save_pretrained(save_loc)\n",
    "        tokenizer.save_pretrained(save_loc)\n",
    "        print(\"Loss is very small\")\n",
    "        break\n",
    "    prev_avg_train_loss = avg_train_loss\n",
    "    model.save_pretrained(save_loc)\n",
    "    tokenizer.save_pretrained(save_loc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
